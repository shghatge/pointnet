{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shghatge/pointnet/blob/master/Feature1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QR9nj5C4_Tyz",
        "colab_type": "code",
        "outputId": "3e2ba065-5d13-417f-fd02-0cf7b2d46d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "import nltk \n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "import pickle\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mCpSoAAT_Z_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dump_to_file(obj, file):\n",
        "    f = open(file,\"wb\")\n",
        "    pickle.dump(obj,f)\n",
        "    f.close()\n",
        "def get_obj(file):\n",
        "    with open(file, 'rb') as handle:\n",
        "        obj = pickle.load(handle)\n",
        "    return obj\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stems = []\n",
        "    for item in tokens:\n",
        "        stems.append(PorterStemmer().stem(item))\n",
        "    return stems\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItPpyDN_BXJr",
        "colab_type": "code",
        "outputId": "39656ba0-d641-456a-e736-e7d59a0f7339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "trainFile = pd.read_csv('TopTenTrain.csv', low_memory=False)\n",
        "testFile = pd.read_csv('TopTenTest.csv', low_memory=False)\n",
        "print('Data Read')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Read\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jw6y20piBmwB",
        "colab_type": "code",
        "outputId": "d8b704e5-c004-43b6-ddc6-72b2f128c09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print(trainFile[\"cleanText\"][108])\n",
        "print(trainFile[\"text\"][108])\n",
        "print(trainFile[\"fillers\"][108])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our state doesnt yet say that \n",
            "Our state doesn't yet, <laughter> say that  /\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HQKOkrW2Boqp",
        "colab_type": "code",
        "outputId": "a1a578ce-03a8-466e-c552-df76d9566e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_corpus_file = 'train_corpus.pkl'\n",
        "test_corpus_file = 'test_corpus.pkl'\n",
        "train_corpus = get_obj(train_corpus_file)\n",
        "test_corpus = get_obj(test_corpus_file)\n",
        "print(train_corpus[:10])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Does say something', 'I think usually', 'Okay', 'Well', 'Okay', 'I', 'It seemed like', 'might', 'I guess', 'Okay']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ko9u-x9CD4Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_dict = dict()\n",
        "labels_dict = dict()\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "for index , row in trainFile.iterrows():\n",
        "    tokens = nltk.word_tokenize(row['cleanText'])\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    l=[]\n",
        "    for tag in tagged:\n",
        "  #    l.append(tag[0])\n",
        "      l.append(tag[1])\n",
        "    pos_dict[index] = \" \".join(l)\n",
        "    labels_dict[index] = row['act_tag']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSPBINr0eIsZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_dict_test = dict()\n",
        "labels_dict_test = dict()\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "for index , row in testFile.iterrows():\n",
        "    tokens = nltk.word_tokenize(row['cleanText'])\n",
        "    tagged = nltk.pos_tag(tokens)\n",
        "    l=[]\n",
        "    for tag in tagged:\n",
        "#       l.append(tag[0])\n",
        "      l.append(tag[1])\n",
        "    pos_dict_test[index] = \" \".join(l)\n",
        "    labels_dict_test[index] = row['act_tag']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qc5HoReJMk2n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus=list(pos_dict.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ClstAqgwO0Tw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "517ca742-66eb-445f-87ad-a7b5e65dd624"
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(tokenizer = tokenize)\n",
        "vectorizer.fit(corpus)\n",
        "vocab = list(vectorizer.vocabulary_.keys()) +list(vectorizer.stop_words_)\n",
        "print(vocab)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['vbz', 'prp', 'vb', 'nn', 'vbp', 'rb', 'vbd', 'in', 'cc', 'md', '$', 'dt', 'cd', 'jj', 'vbg', 'to', 'wp', 'nnp', 'uh', 'wrb', 'vbn', 'jjr', 'ex', 'rp', 'pdt', 'wdt', 'rbr', 'fw', 'po', \"''\", 'sym']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2JdDCSF1ME6m",
        "colab_type": "code",
        "outputId": "44edd47b-3830-4f41-828a-e1e512c48ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(vocab)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "B-Xv_uPxPEWb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_rows = dict()\n",
        "for index , row in trainFile.iterrows():\n",
        "  features_rows[index] = le.transform(tokenize(pos_dict[index].lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "stbRjsF8PYTk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = list(features_rows.values())\n",
        "padded = pad_sequences(features, maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NPtx3_WLeygl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import bisect\n",
        "test_rows = dict()\n",
        "i=0\n",
        "le_classes = le.classes_.tolist()\n",
        "bisect.insort_left(le_classes, 'otherClass')\n",
        "le.classes_ = le_classes\n",
        "for index, row in testFile.iterrows():\n",
        "  test = ['otherClass' if s not in le.classes_ else s for s in tokenize(row['cleanText'].lower())]\n",
        "  test_rows[index] = le.transform(test)\n",
        "X_test = pad_sequences(list(test_rows.values()), maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VpUwmN41dEey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6352b5a-bcda-441d-a6ab-724b53388ea7"
      },
      "cell_type": "code",
      "source": [
        "enc = preprocessing.LabelEncoder()\n",
        "enc.fit(np.array([*labels_dict.values()]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "JBsvW_nPdt-C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = enc.transform(np.array([*labels_dict.values()]))\n",
        "y_test = enc.transform(np.array([*labels_dict_test.values()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TEJz-uZsGA3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = OneVsRestClassifier(RandomForestClassifier(n_estimators=100)).fit(padded, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwaugNW_t5DW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VxzkIItIL-vI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "boO74xjiMBgJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_names = enc.classes_\n",
        "print(classification_report(y_test, preds, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GoNKltssn16r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}